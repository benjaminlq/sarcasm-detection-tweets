{"cells":[{"cell_type":"markdown","source":["# Mount Drive and Install Dependencies"],"metadata":{"id":"tbLyo6sIkdEJ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MccaqAUTwSEa","outputId":"1d406589-f677-42bd-ca56-28486fe822c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","[Errno 2] No such file or directory: '/content/drive/My Drive/group_project/Roberta/'\n","/content\n"]}],"source":["#@title connect google drive folder\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My Drive/group_project/Roberta/\n","\n","from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()\n","\n","!pip install transformers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rzIPO5-0wsbz"},"outputs":[],"source":["#@title Packages and Dependencies\n","import transformers\n","from transformers import BertTokenizer, BertForSequenceClassification, RobertaTokenizer, RobertaForSequenceClassification, AutoTokenizer\n","import torch\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n","from torch.optim import AdamW, lr_scheduler\n","\n","import tqdm, pickle, csv, os, json, math, re\n","from typing import List, Optional, Union\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","transformers.logging.set_verbosity_error()\n","bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"markdown","source":["## Translate emojies encodings to words and export to txt files"],"metadata":{"id":"jVrXIl6jkjR7"}},{"cell_type":"code","source":["# emoji_dict = './Emoji_Dict.p'\n","# with open(emoji_dict, 'rb') as fp:\n","#     Emoji_Dict = pickle.load(fp)\n","# Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n","\n","# def convert_emojis_to_word(text):\n","#     for emot in Emoji_Dict:\n","#         text = re.sub(r'('+emot+')', \"_\".join(Emoji_Dict[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n","#     return text\n","\n","# train_sentences = []\n","# with open('../data/train_emoji.txt', 'r', encoding = 'utf-8') as handle:\n","#     for line in handle:\n","#         train_sentences.append(line)\n","\n","# with open('../data/train_emoji_decode.txt', \"w\", encoding = \"utf-8-sig\") as output:\n","#     for sentence in train_sentences:\n","#         sentence = convert_emojis_to_word(sentence)\n","#         output.write(sentence)\n","\n","# test_sentences = []\n","# with open('../data/test.txt', 'r', encoding = 'utf-8') as handle:\n","#     for line in handle:\n","#         test_sentences.append(line)\n","\n","# with open('../data/test_emoji_decode.txt', \"w\", encoding = \"utf-8-sig\") as output:\n","#     for sentence in test_sentences:\n","#         sentence = convert_emojis_to_word(sentence)\n","#         output.write(sentence)"],"metadata":{"id":"6ewxUk2lfNoN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title PreProcessing\n","class InputExample(object):\n","    \n","    def __init__(self, guid, sentence, label):\n","        self.guid = guid\n","        self.sentence = sentence\n","        self.label = label\n","        \n","    def __str__(self):\n","        return \"Guid: \" + self.guid + \"\\nSentence:\" + self.sentence + \"\\nLabel: \" + self.label\n","\n","class InputFeatures(object):\n","\n","    def __init__(self, input_ids, attention_mask, label=None, token_type_ids = None):\n","        self.input_ids = input_ids\n","        self.attention_mask = attention_mask\n","        self.label = label\n","        if token_type_ids:\n","            self.token_type_ids = token_type_ids\n","\n","    def __str__(self):\n","        return \"Input Ids: \" + str(self.input_ids) + \"\\nAttention Mask:\" + str(self.attention_mask) + \"\\nLabels: \" + str(self.label)\n","        \n","class PreProcessor():\n","    def __init__(self):\n","        self.model_args = {'max_seq_length':64, 'verbose':False}\n","\n","    def set_model_arg(self, key, value):\n","        self.model_args[key] = value\n","    \n","    def get_model_arg(self, key):\n","        return self.model_args.get(key, None)\n","\n","    def save(self, path):\n","        f = open(path, 'wb')\n","        pickle.dump(self, f)\n","        f.close()\n","\n","    def load(self, path):\n","        f = open(path, 'rb')\n","        proc = pickle.load(f)\n","        f.close()\n","        return proc\n","\n","    def _read_txt(self, input_file):\n","        sentences = []\n","        with open(input_file, 'r', encoding = 'utf-8') as handle:\n","            for line in handle:\n","                sentences.append(line)\n","        return sentences\n","\n","    def get_train_examples(self, data_dir, extra_data = False):\n","        if extra_data:\n","            return\n","        return self._create_examples(\n","            self._read_txt(os.path.join(data_dir, \"train_emoji_decode.txt\")))\n","\n","    # def get_dev_examples(self, data_dir):\n","    #     return self._create_examples(\n","    #         self._read_txt(os.path.join(data_dir, \"dev.jsonl\")))\n","    \n","    def get_test_examples(self, data_dir):\n","        return self._create_examples(\n","            self._read_txt(os.path.join(data_dir, \"test_emoji_decode.txt\")))\n","\n","    def _create_examples(self, lines):\n","        examples = []\n","        for (i, line) in enumerate(lines):\n","            if i != 0:\n","                features = line.split('\\t')\n","                sentence = features[2]\n","                label = features[1]\n","                guid = features[0]\n","                examples.append(InputExample(guid = guid, sentence = sentence, label = int(label)))\n","        return examples\n","\n","    def convert_example_to_feature(self, tokenizer, examples):\n","        max_length = proc.get_model_arg(\"max_seq_length\")\n","        features = []\n","\n","        if type(tokenizer) == type(RobertaTokenizer.from_pretrained('roberta-base')):\n","            for example in examples:\n","                inputs = tokenizer(example.sentence, add_special_tokens=True, max_length=max_length, padding = 'max_length')\n","                feature = InputFeatures(input_ids = inputs['input_ids'], attention_mask = inputs[\"attention_mask\"], label = example.label)\n","                features.append(feature)\n","\n","        else:\n","            for example in examples:\n","                inputs = tokenizer(example.sentence, add_special_tokens=True, max_length=max_length, padding = 'max_length')\n","                feature = InputFeatures(input_ids = inputs['input_ids'], attention_mask = inputs[\"attention_mask\"],\n","                                        token_type_ids = inputs['token_type_ids'], label = example.label)\n","                features.append(feature)\n","\n","        return features\n","\n","    def convert_feature_to_dataset(self, features):\n","        # Convert to Tensors and build dataset\n","        \n","        if not hasattr(features[0], 'token_type_ids'):\n","            all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","            all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n","            all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n","            dataset = TensorDataset(all_input_ids, all_attention_mask, all_labels)\n","        else:\n","            all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","            all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n","            all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n","            all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n","            dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n","\n","        return dataset\n","    \n","    def get_dataloader(self, features, batch_size, is_test=False, drop_last=True):\n","        dataset = self.convert_feature_to_dataset(features)\n","        dataset_sampler = SequentialSampler(dataset) if is_test else RandomSampler(dataset)\n","        dataloader = DataLoader(dataset, sampler=dataset_sampler, batch_size=batch_size, drop_last=drop_last)\n","        return dataloader\n","    \n","    def get_data_iter(self, features, batch_size, is_test=False, drop_last=True):\n","        dataloader = self.get_dataloader(features, batch_size, is_test=is_test, drop_last=drop_last)\n","        return iter(dataloader)"],"metadata":{"id":"JaJzXFqZOqNV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KmMT35BStTMm"},"outputs":[],"source":["#@title utility functions\n","\n","def check_gpu():\n","    # torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n","    is_cuda = torch.cuda.is_available()\n","\n","    # If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","    if is_cuda:\n","        device = torch.device(\"cuda\")\n","        print(\"GPU is available\")\n","    else:\n","        device = torch.device(\"cpu\")\n","        print(\"GPU not available, CPU used\")\n","    return device\n","\n","def set_seed(seed=42):\n","    # random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","def save_model(model, path):\n","    torch.save(model.state_dict(), path)\n","\n","def load_model(model, path):\n","    model.load_state_dict(torch.load(path))\n","    return model\n","\n","def test_performance(y_true, y_pred):\n","\n","    # Modify F1-score calculation depending on the task\n","    score = metrics.f1_score(y_true, y_pred, pos_label=1)\n","    p = metrics.precision_score(y_true, y_pred, pos_label=1)\n","    r = metrics.recall_score(y_true, y_pred, pos_label=1)\n","    acc = metrics.accuracy_score(y_true, y_pred)\n","\n","    print('\\n')\n","    print (\"F1-score Task\", score)\n","    print (\"Precision Task\", p)\n","    print (\"Recall Task\", r)\n","    print (\"Accuracy Task\", acc)\n","\n","    false_index = [i for i, x in enumerate(y_pred == y_true) if not x]\n","\n","    return false_index\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sz-CLG1nsdvM"},"outputs":[],"source":["#@title Train\n","def train(model, tokenizer, proc, device, early_stopping = False):\n","\n","    # fetch hyper-parameters\n","    batch_size = proc.get_model_arg(\"batch_size\")\n","    n_epochs = proc.get_model_arg('n_epochs')\n","    learning_rate = proc.get_model_arg(\"learning_rate\")\n","    adam_epsilon = proc.get_model_arg('adam_epsilon')\n","    weight_decay = proc.get_model_arg('weight_decay')\n","    verbose = proc.get_model_arg(\"verbose\")\n","    log_step = proc.get_model_arg(\"log_step\")\n","    checkpoint_path = proc.get_model_arg(\"checkpoint_path\")\n","    max_seq_length = proc.get_model_arg(\"max_seq_length\")\n","    clip = proc.get_model_arg(\"clip\")\n","    data_path = proc.get_model_arg(\"dataset_path\")\n","\n","    # prepare training dataset\n","    examples = proc.get_train_examples(data_path)\n","    features = proc.convert_example_to_feature(tokenizer, examples)\n","    data_iter = proc.get_data_iter(features, batch_size)\n","\n","    # training steps in each epoch\n","    examples_total_num = len(features)\n","    max_steps = math.ceil(float(examples_total_num)/batch_size)\n","    t_total = max_steps * n_epochs\n","    max_val_acc = 0 ## For early stopping\n","\n","    # Define Loss, Optimizer\n","    no_decay = ['bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","        ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n","    scheduler = lr_scheduler.LinearLR(optimizer, total_iters=t_total)\n","\n","    epoch_loss = {'train_loss':[], 'val_accuracy':[]}\n","\n","    if type(tokenizer) == type(bert_tokenizer):\n","        flag = True\n","    else:\n","        flag = False\n","\n","    # train!\n","    for epoch in range(n_epochs):\n","        total_loss = 0.0\n","        pbar = tqdm.tqdm(range(max_steps))\n","        for step in pbar:\n","            model.train()\n","            optimizer.zero_grad() # Clears existing gradients from previous epoch\n","            # prepare inputs\n","            try:\n","                batch = next(data_iter)\n","            except StopIteration:\n","                data_iter = proc.get_data_iter(features, batch_size)\n","                batch = next(data_iter)\n","\n","            batch = tuple(t.to(device) for t in batch)\n","            if flag:\n","                inputs = {'input_ids':      batch[0],\n","                            'attention_mask': batch[1],\n","                            'token_type_ids' : batch[2],\n","                            'labels':         batch[3]}\n","            else:\n","                inputs = {'input_ids':      batch[0],\n","                            'attention_mask': batch[1],\n","                            'labels':         batch[2]}\n","\n","            outputs = model(**inputs)\n","            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n","            loss.backward()\n","            # clip gradients to prevent exploding gradients\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","            optimizer.step()\n","            scheduler.step()  # Update learning rate schedule\n","            \n","            total_loss += loss.item()\n","            if step%log_step==0:\n","                _, val_acc = evaluate(model, tokenizer, proc, device)\n","                print(\"step: {}/{}, Train Loss: {:.4f}, Val Acc: {:.3f}\".format(step, max_steps, loss.item(), val_acc))\n","        \n","        _, val_acc = evaluate(model, tokenizer, proc, device)\n","        print(\"epoch: {}/{}, Train Loss: {:.4f}, Val Accuracy: {}\\n\".format(epoch, n_epochs, total_loss/max_steps, val_acc))\n","        if early_stopping:\n","            if val_acc > max_val_acc:\n","                print('Improved Model saved at,', checkpoint_path)\n","                save_model(model, checkpoint_path)\n","                max_val_acc = val_acc\n","\n","        epoch_loss['train_loss'].append(total_loss/max_steps)\n","        epoch_loss['val_accuracy'].append(val_acc)\n","\n","    # if early_stopping:\n","    #     plt.figure(figsize = (12,6))\n","    #     plt.subplot(1,2,1)\n","    #     plt.plot(epoch_loss['train_loss'], color = 'red')\n","    #     plt.xlabel('Epoch')\n","    #     plt.ylabel('Train Loss')\n","    #     plt.title('Training Loss')\n","    #     plt.subplot(1,2,2)\n","    #     plt.plot(epoch_loss['val_accuracy'], color = 'blue')   \n","    #     plt.xlabel('Epoch')\n","    #     plt.ylabel('Validation Accuracy')\n","    #     plt.title('Validation Accuracy') \n","    #     plt.show()\n","\n","    if not early_stopping:\n","        print('Only save final model')\n","        save_model(model, checkpoint_path)\n","    \n","    return epoch_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GNzLrfud8zti"},"outputs":[],"source":["#@title Evaluate on dev set\n","def evaluate(model, tokenizer, proc, device):\n","    # fetch hyper-parameters\n","    batch_size = proc.get_model_arg(\"batch_size\")\n","    n_epochs = proc.get_model_arg('n_epochs')\n","    learning_rate = proc.get_model_arg(\"learning_rate\")\n","    adam_epsilon = proc.get_model_arg('adam_epsilon')\n","    weight_decay = proc.get_model_arg('weight_decay')\n","    verbose = proc.get_model_arg(\"verbose\")\n","    log_step = proc.get_model_arg(\"log_step\")\n","    checkpoint_path = proc.get_model_arg(\"checkpoint_path\")\n","    max_seq_length = proc.get_model_arg(\"max_seq_length\")\n","    clip = proc.get_model_arg(\"clip\")\n","    data_path = proc.get_model_arg(\"dataset_path\")\n","    \n","    # prepare dataset\n","\n","    correct_counter = 0\n","    examples = proc.get_test_examples(data_path)\n","    sample_size = len(examples)\n","    features = proc.convert_example_to_feature(tokenizer, examples)\n","    eval_dataloader = proc.get_dataloader(features, batch_size, is_test = True,\n","                                          drop_last = False)\n","\n","    all_predictions = []\n","\n","    if type(tokenizer) == type(bert_tokenizer):\n","        flag = True\n","    else:\n","        flag = False\n","\n","    model.eval()\n","    for batch in eval_dataloader:\n","        \n","        batch = tuple(t.to(device) for t in batch)\n","\n","        with torch.no_grad():\n","            if flag:\n","                inputs = {'input_ids':      batch[0],\n","                            'attention_mask': batch[1],\n","                            'token_type_ids' : batch[2],\n","                            'labels':         batch[3]}\n","            else:\n","                inputs = {'input_ids':      batch[0],\n","                            'attention_mask': batch[1],\n","                            'labels':         batch[2]}\n","            outputs = model(**inputs)\n","            predictions = outputs.logits.argmax(dim=-1)\n","            correct_counter += (predictions == inputs['labels']).sum()\n","        all_predictions.extend(list(predictions.clone().detach().to('cpu')))\n","    accuracy = correct_counter/sample_size\n","    # print('Validation Accuracy:', accuracy)\n","\n","    return np.array(all_predictions), accuracy"]},{"cell_type":"markdown","metadata":{"id":"05zyJ0nJGZML"},"source":["# Training and Prediction\n","\n","## Base HyperParameters:\n","\n","proc.set_model_arg('batch_size', 64) <br>\n","proc.set_model_arg('max_seq_length', 128) <br>\n","proc.set_model_arg('learning_rate', 2e-5) <br>\n","proc.set_model_arg('n_epochs', 20) <br>\n","proc.set_model_arg('warmup_steps', 0.06) <br>\n","proc.set_model_arg('weight_decay', 0.1) <br>\n","proc.set_model_arg('adam_epsilon', 1e-8) <br>\n","proc.set_model_arg('clip', 1) <br>\n","proc.set_model_arg('log_step', 128) <br>\n","proc.set_model_arg('init_seed', 42) <br>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VMc7sTgDWu0_"},"outputs":[],"source":["#@title Setup Preprocessor with hyperparameters settings\n","# preprare dataset and hyper-parameters for training\n","proc = PreProcessor()\n","\n","# hyper-parameters for data\n","proc.set_model_arg('batch_size', 64)\n","proc.set_model_arg('max_seq_length', 128)\n","\n","# hyper-parameters for model\n","proc.set_model_arg('learning_rate', 2e-5)\n","proc.set_model_arg('n_epochs', 20)\n","proc.set_model_arg('warmup_steps', 0.06)\n","proc.set_model_arg('weight_decay', 0.1)\n","proc.set_model_arg('adam_epsilon', 1e-8)\n","proc.set_model_arg('clip', 1)\n","\n","# arguments for reproduction\n","proc.set_model_arg('log_step', 128)\n","proc.set_model_arg('verbose', True)    # if log details\n","proc.set_model_arg('init_seed', 42)\n","proc.set_model_arg('checkpoint_path', \"./model_checkpoint/roberta.bin\")\n","proc.set_model_arg('dataset_path', \"./data/\")\n","\n","# save proc\n","arg_path = \"./procs/proc.dat\"\n","proc.save(arg_path)\n"]},{"cell_type":"code","source":["#@title Bert-Base-Uncased\n","proc.set_model_arg('batch_size', 64)\n","proc.set_model_arg('checkpoint_path', \"./model_checkpoint/bert-base.bin\")\n","pre_trained_model = \"bert-base-uncased\"\n","\n","tokenizer = BertTokenizer.from_pretrained(pre_trained_model)\n","model = BertForSequenceClassification.from_pretrained(pre_trained_model)\n","\n","# get parameters from preprocessor\n","init_seed = proc.get_model_arg('init_seed')\n","proc.set_model_arg('verbose', False)\n","\n","device = check_gpu()\n","set_seed(init_seed)\n","\n","# We'll also set the model to the device that we defined earlier (default is CPU)\n","model = model.to(device)\n","epoch_loss = train(model, tokenizer, proc, device,\n","                   early_stopping = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8EVzJjckVXyW","executionInfo":{"status":"ok","timestamp":1655180639957,"user_tz":-480,"elapsed":1067060,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"a5b24299-f3f5-48b4-9cfa-4c904639f440"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:07<06:55,  7.04s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.7881, Val Acc: 0.398\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:48<00:00,  1.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 0/20, Train Loss: 0.6715, Val Accuracy: 0.6313775181770325\n","\n","Improved Model saved at, ./model_checkpoint/bert-base.bin\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:35,  5.69s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.6219, Val Acc: 0.639\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 1/20, Train Loss: 0.6152, Val Accuracy: 0.6505101919174194\n","\n","Improved Model saved at, ./model_checkpoint/bert-base.bin\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:36,  5.71s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.5136, Val Acc: 0.639\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 2/20, Train Loss: 0.5659, Val Accuracy: 0.6658163070678711\n","\n","Improved Model saved at, ./model_checkpoint/bert-base.bin\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:36,  5.70s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.4683, Val Acc: 0.666\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 3/20, Train Loss: 0.5014, Val Accuracy: 0.6619898080825806\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:35,  5.69s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.5962, Val Acc: 0.639\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 4/20, Train Loss: 0.4390, Val Accuracy: 0.6875\n","\n","Improved Model saved at, ./model_checkpoint/bert-base.bin\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:36,  5.70s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.3542, Val Acc: 0.685\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 5/20, Train Loss: 0.3558, Val Accuracy: 0.6760203838348389\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:34,  5.68s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.3116, Val Acc: 0.676\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 6/20, Train Loss: 0.2993, Val Accuracy: 0.6543367505073547\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:35,  5.68s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.2293, Val Acc: 0.653\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 7/20, Train Loss: 0.2265, Val Accuracy: 0.7053571343421936\n","\n","Improved Model saved at, ./model_checkpoint/bert-base.bin\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:33,  5.66s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.1213, Val Acc: 0.707\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 8/20, Train Loss: 0.1830, Val Accuracy: 0.6760203838348389\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:35,  5.69s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.1034, Val Acc: 0.675\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 9/20, Train Loss: 0.1439, Val Accuracy: 0.6785714030265808\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:35,  5.69s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.1087, Val Acc: 0.679\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 10/20, Train Loss: 0.1184, Val Accuracy: 0.6581632494926453\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:35,  5.69s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.0952, Val Acc: 0.666\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 11/20, Train Loss: 0.0968, Val Accuracy: 0.6977040767669678\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:36,  5.71s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.1010, Val Acc: 0.700\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 12/20, Train Loss: 0.0651, Val Accuracy: 0.6951530575752258\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:34,  5.68s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.0422, Val Acc: 0.698\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 13/20, Train Loss: 0.0507, Val Accuracy: 0.6619898080825806\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:34,  5.67s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.0088, Val Acc: 0.656\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 14/20, Train Loss: 0.0528, Val Accuracy: 0.7130101919174194\n","\n","Improved Model saved at, ./model_checkpoint/bert-base.bin\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:35,  5.69s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.0120, Val Acc: 0.705\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 15/20, Train Loss: 0.0466, Val Accuracy: 0.6632652878761292\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:34,  5.68s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.0739, Val Acc: 0.649\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 16/20, Train Loss: 0.0464, Val Accuracy: 0.7002550959587097\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:35,  5.68s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.0038, Val Acc: 0.694\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 17/20, Train Loss: 0.0373, Val Accuracy: 0.668367326259613\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:35,  5.69s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.0051, Val Acc: 0.684\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 18/20, Train Loss: 0.0254, Val Accuracy: 0.6823979616165161\n","\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/60 [00:05<05:35,  5.68s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/60, Train Loss: 0.1058, Val Acc: 0.676\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:47<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 19/20, Train Loss: 0.0279, Val Accuracy: 0.6823979616165161\n","\n"]}]},{"cell_type":"code","source":["#@title Bert-Large\n","proc.set_model_arg('batch_size', 32)\n","proc.set_model_arg('checkpoint_path', \"./model_checkpoint/bert-large.bin\")\n","pre_trained_model = \"bert-large-uncased\"\n","\n","tokenizer = BertTokenizer.from_pretrained(pre_trained_model)\n","model = BertForSequenceClassification.from_pretrained(pre_trained_model)\n","\n","# get parameters from preprocessor\n","init_seed = proc.get_model_arg('init_seed')\n","proc.set_model_arg('verbose', False)\n","\n","device = check_gpu()\n","set_seed(init_seed)\n","\n","# We'll also set the model to the device that we defined earlier (default is CPU)\n","model = model.to(device)\n","epoch_loss = train(model, tokenizer, proc, device,\n","                   early_stopping = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1vfetVvdYVAS","executionInfo":{"status":"ok","timestamp":1655185604154,"user_tz":-480,"elapsed":3457074,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"b2610772-c667-4f07-89d8-c3716d29840a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:29, 12.85s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 1.2464, Val Acc: 0.397\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:39<00:00,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 0/20, Train Loss: 0.6651, Val Accuracy: 0.7053571343421936\n","\n","Improved Model saved at, ./model_checkpoint/bert-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:30, 12.86s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.5354, Val Acc: 0.707\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:39<00:00,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 1/20, Train Loss: 0.5684, Val Accuracy: 0.6772959232330322\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:25, 12.82s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.3893, Val Acc: 0.676\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 2/20, Train Loss: 0.4582, Val Accuracy: 0.6887754797935486\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:24, 12.81s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.5087, Val Acc: 0.689\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 3/20, Train Loss: 0.3428, Val Accuracy: 0.6926020383834839\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:13<26:31, 13.37s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.3510, Val Acc: 0.699\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 4/20, Train Loss: 0.2587, Val Accuracy: 0.7270408272743225\n","\n","Improved Model saved at, ./model_checkpoint/bert-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:13<26:41, 13.46s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0789, Val Acc: 0.732\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:39<00:00,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 5/20, Train Loss: 0.1934, Val Accuracy: 0.7270408272743225\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:26, 12.82s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.1917, Val Acc: 0.739\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:39<00:00,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 6/20, Train Loss: 0.1535, Val Accuracy: 0.7028061151504517\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:24, 12.81s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0306, Val Acc: 0.690\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 7/20, Train Loss: 0.1003, Val Accuracy: 0.6926020383834839\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:23, 12.81s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.1186, Val Acc: 0.705\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 8/20, Train Loss: 0.0747, Val Accuracy: 0.7028061151504517\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:24, 12.81s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.2294, Val Acc: 0.700\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 9/20, Train Loss: 0.0637, Val Accuracy: 0.7359693646430969\n","\n","Improved Model saved at, ./model_checkpoint/bert-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:34, 12.89s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.2101, Val Acc: 0.744\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 10/20, Train Loss: 0.0696, Val Accuracy: 0.733418345451355\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:23, 12.80s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0097, Val Acc: 0.732\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:37<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 11/20, Train Loss: 0.0602, Val Accuracy: 0.7372449040412903\n","\n","Improved Model saved at, ./model_checkpoint/bert-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:21, 12.78s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0009, Val Acc: 0.739\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 12/20, Train Loss: 0.0409, Val Accuracy: 0.7436224222183228\n","\n","Improved Model saved at, ./model_checkpoint/bert-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:22, 12.80s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0015, Val Acc: 0.746\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:37<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 13/20, Train Loss: 0.0426, Val Accuracy: 0.7359693646430969\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:13, 12.72s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0008, Val Acc: 0.726\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:37<00:00,  1.31s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 14/20, Train Loss: 0.0576, Val Accuracy: 0.7015305757522583\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:13, 12.71s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0072, Val Acc: 0.693\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 15/20, Train Loss: 0.0367, Val Accuracy: 0.7512754797935486\n","\n","Improved Model saved at, ./model_checkpoint/bert-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:24, 12.81s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0131, Val Acc: 0.749\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:40<00:00,  1.34s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 16/20, Train Loss: 0.0416, Val Accuracy: 0.7397959232330322\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:10, 12.70s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0012, Val Acc: 0.746\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:39<00:00,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 17/20, Train Loss: 0.0392, Val Accuracy: 0.75\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:13<26:12, 13.22s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0005, Val Acc: 0.759\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 18/20, Train Loss: 0.0362, Val Accuracy: 0.7436224222183228\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:10, 12.69s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0116, Val Acc: 0.745\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:37<00:00,  1.31s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 19/20, Train Loss: 0.0335, Val Accuracy: 0.730867326259613\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIcyMXn43C94","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655188313660,"user_tz":-480,"elapsed":1126515,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"92452960-e776-4b8a-c8ee-6148eeeb1344"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/120 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  1%|          | 1/120 [00:05<10:50,  5.47s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.2304, Val Acc: 0.737\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 0/20, Train Loss: 0.2494, Val Accuracy: 0.7040815949440002\n","\n","Improved Model saved at, ./model_checkpoint/roberta_pretrained.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:08,  5.11s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.1363, Val Acc: 0.704\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:51<00:00,  2.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 1/20, Train Loss: 0.1664, Val Accuracy: 0.7563775181770325\n","\n","Improved Model saved at, ./model_checkpoint/roberta_pretrained.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:11,  5.14s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.1776, Val Acc: 0.756\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 2/20, Train Loss: 0.1171, Val Accuracy: 0.7244898080825806\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:08,  5.11s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.1134, Val Acc: 0.722\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 3/20, Train Loss: 0.0813, Val Accuracy: 0.7665815949440002\n","\n","Improved Model saved at, ./model_checkpoint/roberta_pretrained.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:10,  5.13s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.1764, Val Acc: 0.765\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 4/20, Train Loss: 0.0547, Val Accuracy: 0.730867326259613\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:12,  5.15s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0066, Val Acc: 0.731\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 5/20, Train Loss: 0.0290, Val Accuracy: 0.7831632494926453\n","\n","Improved Model saved at, ./model_checkpoint/roberta_pretrained.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:10,  5.13s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0005, Val Acc: 0.779\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 6/20, Train Loss: 0.0197, Val Accuracy: 0.7563775181770325\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:09,  5.12s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0002, Val Acc: 0.755\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 7/20, Train Loss: 0.0148, Val Accuracy: 0.7372449040412903\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:10,  5.13s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0003, Val Acc: 0.737\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 8/20, Train Loss: 0.0152, Val Accuracy: 0.7614795565605164\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:08,  5.11s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0002, Val Acc: 0.763\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 9/20, Train Loss: 0.0144, Val Accuracy: 0.7512754797935486\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:08,  5.12s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0006, Val Acc: 0.758\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 10/20, Train Loss: 0.0077, Val Accuracy: 0.714285671710968\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:08,  5.11s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0000, Val Acc: 0.717\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 11/20, Train Loss: 0.0063, Val Accuracy: 0.733418345451355\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:11,  5.13s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0000, Val Acc: 0.728\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 12/20, Train Loss: 0.0162, Val Accuracy: 0.7130101919174194\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:12,  5.15s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0002, Val Acc: 0.716\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 13/20, Train Loss: 0.0131, Val Accuracy: 0.7244898080825806\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:11,  5.14s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0000, Val Acc: 0.724\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 14/20, Train Loss: 0.0144, Val Accuracy: 0.7461734414100647\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:09,  5.12s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0000, Val Acc: 0.750\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 15/20, Train Loss: 0.0169, Val Accuracy: 0.7806122303009033\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:33,  5.33s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0000, Val Acc: 0.777\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 16/20, Train Loss: 0.0111, Val Accuracy: 0.7576530575752258\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:08,  5.11s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0000, Val Acc: 0.756\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 17/20, Train Loss: 0.0162, Val Accuracy: 0.7716836333274841\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:09,  5.12s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0000, Val Acc: 0.760\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 18/20, Train Loss: 0.0113, Val Accuracy: 0.7474489808082581\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:05<10:07,  5.11s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0000, Val Acc: 0.747\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:50<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 19/20, Train Loss: 0.0190, Val Accuracy: 0.7487244606018066\n","\n"]}],"source":["#@title Roberta-With-Pretrained-Weights\n","proc.set_model_arg('batch_size', 32)\n","proc.set_model_arg('checkpoint_path', \"./model_checkpoint/roberta_pretrained.bin\")\n","pre_trained_model = \"cardiffnlp/twitter-roberta-base-irony\"\n","\n","tokenizer = RobertaTokenizer.from_pretrained(pre_trained_model)\n","model = RobertaForSequenceClassification.from_pretrained(pre_trained_model)\n","\n","# get parameters from preprocessor\n","init_seed = proc.get_model_arg('init_seed')\n","proc.set_model_arg('verbose', False)\n","\n","device = check_gpu()\n","set_seed(init_seed)\n","\n","# We'll also set the model to the device that we defined earlier (default is CPU)\n","model = model.to(device)\n","epoch_loss = train(model, tokenizer, proc, device,\n","                   early_stopping = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bl80xR_HQj-y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655191895155,"user_tz":-480,"elapsed":3457318,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"a809c5c1-bb04-44c5-8a23-1d5d8a36b430"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:42, 12.96s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.6979, Val Acc: 0.603\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 0/20, Train Loss: 0.4503, Val Accuracy: 0.605867326259613\n","\n","Improved Model saved at, ./model_checkpoint/roberta-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:49, 12.52s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.2698, Val Acc: 0.606\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 1/20, Train Loss: 0.2703, Val Accuracy: 0.6045918464660645\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:44, 12.47s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0721, Val Acc: 0.602\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:37<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 2/20, Train Loss: 0.2167, Val Accuracy: 0.6071428656578064\n","\n","Improved Model saved at, ./model_checkpoint/roberta-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:47, 12.50s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.3244, Val Acc: 0.607\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:37<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 3/20, Train Loss: 0.1770, Val Accuracy: 0.6071428656578064\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:45, 12.48s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.2594, Val Acc: 0.607\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:37<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 4/20, Train Loss: 0.1646, Val Accuracy: 0.6160714030265808\n","\n","Improved Model saved at, ./model_checkpoint/roberta-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:53, 12.55s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.1383, Val Acc: 0.615\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 5/20, Train Loss: 0.1221, Val Accuracy: 0.6135203838348389\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:50, 12.53s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0092, Val Acc: 0.612\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 6/20, Train Loss: 0.0987, Val Accuracy: 0.6211734414100647\n","\n","Improved Model saved at, ./model_checkpoint/roberta-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:54, 12.56s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.1489, Val Acc: 0.626\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 7/20, Train Loss: 0.0892, Val Accuracy: 0.6594387888908386\n","\n","Improved Model saved at, ./model_checkpoint/roberta-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:56, 12.58s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0007, Val Acc: 0.659\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 8/20, Train Loss: 0.0791, Val Accuracy: 0.6530612111091614\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:45, 12.48s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0014, Val Acc: 0.657\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:37<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 9/20, Train Loss: 0.0661, Val Accuracy: 0.6262754797935486\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:46, 12.49s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0320, Val Acc: 0.631\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:37<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 10/20, Train Loss: 0.0414, Val Accuracy: 0.6747449040412903\n","\n","Improved Model saved at, ./model_checkpoint/roberta-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:16, 12.75s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0193, Val Acc: 0.670\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 11/20, Train Loss: 0.0428, Val Accuracy: 0.6619898080825806\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:46, 12.49s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.2397, Val Acc: 0.657\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:37<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 12/20, Train Loss: 0.0286, Val Accuracy: 0.6288264989852905\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:46, 12.49s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.2801, Val Acc: 0.630\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:37<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 13/20, Train Loss: 0.0216, Val Accuracy: 0.6390305757522583\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<24:50, 12.52s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0001, Val Acc: 0.639\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 14/20, Train Loss: 0.0237, Val Accuracy: 0.6390305757522583\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:01, 12.61s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0001, Val Acc: 0.639\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 15/20, Train Loss: 0.0377, Val Accuracy: 0.6352040767669678\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:01, 12.62s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0001, Val Acc: 0.640\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:39<00:00,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 16/20, Train Loss: 0.0271, Val Accuracy: 0.6938775181770325\n","\n","Improved Model saved at, ./model_checkpoint/roberta-large.bin\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:17, 12.75s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0001, Val Acc: 0.693\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:40<00:00,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 17/20, Train Loss: 0.0369, Val Accuracy: 0.6594387888908386\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:12, 12.71s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0001, Val Acc: 0.649\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:39<00:00,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 18/20, Train Loss: 0.0361, Val Accuracy: 0.625\n","\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/120 [00:12<25:09, 12.69s/it]"]},{"output_type":"stream","name":"stdout","text":["step: 0/120, Train Loss: 0.0002, Val Acc: 0.625\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [02:39<00:00,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 19/20, Train Loss: 0.0413, Val Accuracy: 0.6211734414100647\n","\n"]}],"source":["#@title Roberta-large-from-scratch\n","pre_trained_model = \"roberta-large\"\n","proc.set_model_arg('batch_size', 32)\n","proc.set_model_arg('checkpoint_path', \"./model_checkpoint/roberta-large.bin\")\n","\n","tokenizer = RobertaTokenizer.from_pretrained(pre_trained_model)\n","model = RobertaForSequenceClassification.from_pretrained(pre_trained_model)\n","\n","# get parameters from preprocessor\n","init_seed = proc.get_model_arg('init_seed')\n","proc.set_model_arg('verbose', False)\n","\n","device = check_gpu()\n","set_seed(init_seed)\n","\n","# We'll also set the model to the device that we defined earlier (default is CPU)\n","model = model.to(device)\n","epoch_loss = train(model, tokenizer, proc, device,\n","                   early_stopping = True)"]},{"cell_type":"markdown","source":["# Models Evaluation and Error Analysis"],"metadata":{"id":"_CV9wtWKlYZX"}},{"cell_type":"code","source":["## Get the test labels\n","examples = proc.get_test_examples(proc.get_model_arg('dataset_path'))\n","test_labels = []\n","for example in examples:\n","    test_labels.append(example.label)\n","\n","test_labels = np.array(test_labels)"],"metadata":{"id":"u7o1k5CcuAk7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Bert-Base-Uncased"],"metadata":{"id":"LjAZrYDBmPGy"}},{"cell_type":"code","source":["model_path = \"./model_checkpoint/bert-base.bin\"\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n","model = load_model (model, model_path)\n","model.to(device)\n","\n","predictions, _ = evaluate(model, tokenizer, proc, device)\n","\n","# Evaluate Test Result\n","bert_base_false_index = test_performance(test_labels, predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aeVFUYCAldVK","executionInfo":{"status":"ok","timestamp":1655186451073,"user_tz":-480,"elapsed":9174,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"a18139d4-ad52-432e-b08d-5cdec547064b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","F1-score Task 0.6388443017656501\n","Precision Task 0.6378205128205128\n","Recall Task 0.639871382636656\n","Accuracy Task 0.7130102040816326\n"]}]},{"cell_type":"markdown","source":["## Bert-Large"],"metadata":{"id":"wAjTxFiVuDCP"}},{"cell_type":"code","source":["model_path = \"./model_checkpoint/bert-large.bin\"\n","tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n","model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\")\n","model = load_model (model, model_path)\n","model.to(device)\n","\n","predictions, _ = evaluate(model, tokenizer, proc, device)\n","\n","# Evaluate Test Result\n","bert_large_false_index = test_performance(test_labels, predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"buiHGON_t5co","executionInfo":{"status":"ok","timestamp":1655187089956,"user_tz":-480,"elapsed":33093,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"30762a90-4f57-45c5-f472-940ec8937e5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","F1-score Task 0.7202295552367288\n","Precision Task 0.6502590673575129\n","Recall Task 0.8070739549839229\n","Accuracy Task 0.7512755102040817\n"]}]},{"cell_type":"markdown","source":["## Roberta-Large"],"metadata":{"id":"Pb4b9G5IuQDf"}},{"cell_type":"code","source":["model_path = \"./model_checkpoint/roberta-large.bin\"\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")\n","model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\")\n","model = load_model (model, model_path)\n","model.to(device)\n","\n","predictions, _ = evaluate(model, tokenizer, proc, device)\n","\n","# Evaluate Test Result\n","roberta_large_false_index = test_performance(test_labels, predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6XY-J9vuQfP","executionInfo":{"status":"ok","timestamp":1655192020143,"user_tz":-480,"elapsed":37083,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"fec70056-bf31-406b-cad2-3b86316ddfa5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","F1-score Task 0.42028985507246375\n","Precision Task 0.8446601941747572\n","Recall Task 0.2797427652733119\n","Accuracy Task 0.6938775510204082\n"]}]},{"cell_type":"markdown","source":["## Roberta with pretrained weights"],"metadata":{"id":"xTNoIJIpugl1"}},{"cell_type":"code","source":["model_path = \"./model_checkpoint/roberta_pretrained.bin\"\n","tokenizer = RobertaTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-irony\")\n","model = RobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-irony\")\n","model = load_model (model, model_path)\n","model.to(device)\n","\n","predictions, _ = evaluate(model, tokenizer, proc, device)\n","\n","# Evaluate Test Result\n","roberta_large_false_index = test_performance(test_labels, predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOd7BjWkugMf","executionInfo":{"status":"ok","timestamp":1655188325093,"user_tz":-480,"elapsed":10319,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"4e44798a-7f92-411d-a0d3-aceed63d4a26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","F1-score Task 0.6613545816733067\n","Precision Task 0.8691099476439791\n","Recall Task 0.5337620578778135\n","Accuracy Task 0.7831632653061225\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Bert and Roberta.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}